{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import scipy.integrate as scp\n",
    "import numpy.random as rnd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rnd\n",
    "import copy\n",
    "from matplotlib.pyplot import figure\n",
    "from pyomo.environ import *\n",
    "from pyomo.dae import *\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy.stats\n",
    "from math import comb\n",
    "from numpy.polynomial import polynomial as P\n",
    "from scipy.integrate import odeint\n",
    "from pyomo.environ import ConstraintList\n",
    "\n",
    "eps  = np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "''' Data treatment'''\n",
    "def save_pkl(item, fname):\n",
    "    sn = 'tmp7/' + fname\n",
    "    with open(sn, 'wb') as handle:\n",
    "        pickle.dump(item, handle) #, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(f'File saved at: {sn}')\n",
    "    return None\n",
    "# return None\n",
    "\n",
    "def load_pkl(fname):\n",
    "    with open(fname, 'rb') as handle:\n",
    "        ans = pickle.load(handle)\n",
    "    print(f'Loaded from: {fname}')\n",
    "    return ans\n",
    "\n",
    "def to_dict(x,dt):\n",
    "    obs = list(x)\n",
    "    # tp = list(time)\n",
    "    dicx = {}\n",
    "    for i in range(len(x)):\n",
    "        dicx[dt*i] = obs[i]            # change thye value of 38.4\n",
    "    return dicx\n",
    "\n",
    "def get_grad(x, t):\n",
    "    dxdt = [[],[],[],[]]\n",
    "    for n in range(x.shape[0]):\n",
    "        for i in range(len(x[0]) - 1):\n",
    "            dxdt[n].append((x[n][i + 1] - x[n][i])/(t[i + 1] - t[i]))\n",
    "        dxdt[n].append(dxdt[n][-1])\n",
    "    return dxdt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eff_neuron = 7# actually applied number of neurons\n",
    "no_euron = 7 # total number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from: data/xobs1.pkl\n",
      "Loaded from: data/xobs2.pkl\n",
      "Loaded from: data/xobs3.pkl\n",
      "Loaded from: data/xobs4.pkl\n",
      "Loaded from: data/u_con.pkl\n",
      "Loaded from: data/tf_N.pkl\n",
      "Loaded from: data/N_in.pkl\n",
      "Loaded from: data/operation_con.pkl\n",
      "Loaded from: data/tt1.pkl\n",
      "Loaded from: data/std_value1.pkl\n",
      "Loaded from: data/std_value2.pkl\n",
      "Loaded from: data/std_value3.pkl\n",
      "Loaded from: data/std_value4.pkl\n",
      "Loaded from: data/data_init.pkl\n"
     ]
    }
   ],
   "source": [
    "xobs1 = load_pkl('data/xobs1.pkl')\n",
    "xobs2 = load_pkl('data/xobs2.pkl')\n",
    "xobs3 = load_pkl('data/xobs3.pkl')\n",
    "xobs4 = load_pkl('data/xobs4.pkl')\n",
    "mu_con   = load_pkl('data/u_con.pkl')\n",
    "tf_N  = load_pkl('data/tf_N.pkl')\n",
    "N_in  = load_pkl('data/N_in.pkl')\n",
    "operation_con = load_pkl('data/operation_con.pkl')\n",
    "\n",
    "\n",
    "tt1 = load_pkl('data/tt1.pkl')\n",
    "std_value1 = load_pkl('data/std_value1.pkl')\n",
    "std_value2 = load_pkl('data/std_value2.pkl')\n",
    "std_value3 = load_pkl('data/std_value3.pkl')\n",
    "std_value4 = load_pkl('data/std_value4.pkl')\n",
    "data_init = load_pkl('data/data_init.pkl')\n",
    "\n",
    "operation_con1 = operation_con[0]\n",
    "operation_con2 = operation_con[1]\n",
    "operation_con3 = operation_con[2]\n",
    "operation_con4 = operation_con[3]\n",
    "\n",
    "mu1 = mu_con[0] #u contains FNin and I0\n",
    "mu2 = mu_con[1] \n",
    "mu3 = mu_con[2] \n",
    "mu4 = mu_con[3] \n",
    "\n",
    "tf    = 240\n",
    "# tf    = 16*24\n",
    "steps_= 10\n",
    "dt    = tf/steps_ #dt is fixed\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xobs1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.  ],\n",
       "       [32.5 ],\n",
       "       [41.25],\n",
       "       [23.75]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operation_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_max = np.max(np.array([xobs1[0],xobs2[0],xobs3[0],xobs4[0]]))\n",
    "q_max = np.max(np.array([xobs1[2],xobs2[2],xobs3[2],xobs4[2]]))\n",
    "I_max = np.max(np.concatenate(mu_con).T[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193.75"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I_max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xobs1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_N = 4\n",
    "tf_N  = tf/(num_N)\n",
    "dstep_N = int(tf_N/dt)\n",
    "\n",
    "def get_grad(x, t):\n",
    "    dxdt = [[],[],[],[],[]]\n",
    "    for n in range(x.shape[0]):\n",
    "        for i in range(len(x[0]) - 1):\n",
    "            dxdt[n].append((x[n][i + 1] - x[n][i])/(t[i + 1] - t[i]))\n",
    "        dxdt[n].append(dxdt[n][-1])\n",
    "    return dxdt\n",
    "\n",
    "Xt1   = [to_dict(xobs1[0],dt), to_dict(xobs1[1],dt), to_dict(xobs1[2],dt), to_dict(xobs1[3],dt), to_dict(xobs1[4],dt)] \n",
    "dXdt1 = [to_dict(get_grad(xobs1, tt1)[0],dt),to_dict(get_grad(xobs1, tt1)[1],dt),to_dict(get_grad(xobs1, tt1)[2],dt),to_dict(get_grad(xobs1, tt1)[3],dt),to_dict(get_grad(xobs1, tt1)[4],dt)]\n",
    "Xt2   = [to_dict(xobs2[0],dt), to_dict(xobs2[1],dt), to_dict(xobs2[2],dt), to_dict(xobs2[3],dt), to_dict(xobs2[4],dt)] \n",
    "dXdt2 = [to_dict(get_grad(xobs2, tt1)[0],dt),to_dict(get_grad(xobs2, tt1)[1],dt),to_dict(get_grad(xobs2, tt1)[2],dt),to_dict(get_grad(xobs2, tt1)[3],dt),to_dict(get_grad(xobs2, tt1)[4],dt)]\n",
    "Xt3   = [to_dict(xobs3[0],dt), to_dict(xobs3[1],dt), to_dict(xobs3[2],dt), to_dict(xobs3[3],dt), to_dict(xobs3[4],dt)] \n",
    "dXdt3 = [to_dict(get_grad(xobs3, tt1)[0],dt),to_dict(get_grad(xobs3, tt1)[1],dt),to_dict(get_grad(xobs3, tt1)[2],dt),to_dict(get_grad(xobs3, tt1)[3],dt),to_dict(get_grad(xobs3, tt1)[4],dt)]\n",
    "Xt4   = [to_dict(xobs4[0],dt), to_dict(xobs4[1],dt), to_dict(xobs4[2],dt), to_dict(xobs4[3],dt), to_dict(xobs4[4],dt)] \n",
    "dXdt4 = [to_dict(get_grad(xobs4, tt1)[0],dt),to_dict(get_grad(xobs4, tt1)[1],dt),to_dict(get_grad(xobs4, tt1)[2],dt),to_dict(get_grad(xobs4, tt1)[3],dt),to_dict(get_grad(xobs4, tt1)[4],dt)]\n",
    "# Xt5   = [to_dict(xobs5[0],dt), to_dict(xobs5[1],dt), to_dict(xobs5[2],dt), to_dict(xobs5[3],dt)] \n",
    "# dXdt5 = [to_dict(get_grad(xobs5, tt1)[0],dt),to_dict(get_grad(xobs5, tt1)[1],dt),to_dict(get_grad(xobs5, tt1)[2],dt),to_dict(get_grad(xobs5, tt1)[3],dt)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0.18,\n",
       " 24.0: 0.5788791079922703,\n",
       " 48.0: 0.8752425776444962,\n",
       " 72.0: 1.0945883131292757,\n",
       " 96.0: 1.2471987458761729,\n",
       " 120.0: 1.1714276107187842,\n",
       " 144.0: 1.1280349920412818,\n",
       " 168.0: 1.0868458644603565,\n",
       " 192.0: 1.2873534882601663,\n",
       " 216.0: 1.3685201162402763,\n",
       " 240.0: 1.3910202506917433}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1 = operation_con[0]\n",
    "N2 = operation_con[1]\n",
    "N3 = operation_con[2]\n",
    "N4 = operation_con[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ipopt 3.12.13: max_iter=100000\n",
      "tol=1e-09\n",
      "\n",
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit http://projects.coin-or.org/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "This is Ipopt version 3.12.13, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:    20295\n",
      "Number of nonzeros in inequality constraint Jacobian.:      151\n",
      "Number of nonzeros in Lagrangian Hessian.............:    19181\n",
      "\n",
      "Error in an AMPL evaluation. Run with \"halt_on_ampl_error yes\" to see details.\n",
      "Error evaluating Jacobian of equality constraints at user provided starting point.\n",
      "  No scaling factors for equality constraints computed!\n",
      "Error in an AMPL evaluation. Run with \"halt_on_ampl_error yes\" to see details.\n",
      "Error evaluating Jacobian of inequality constraints at user provided starting point.\n",
      "  No scaling factors for inequality constraints computed!\n",
      "Total number of variables............................:     3052\n",
      "                     variables with only lower bounds:     1052\n",
      "                variables with lower and upper bounds:     1250\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:     3010\n",
      "Total number of inequality constraints...............:      151\n",
      "        inequality constraints with only lower bounds:      151\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  3.4427308e+02 1.00e+04 1.03e+00  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  3.4427291e+02 1.00e+04 6.33e+00  -1.0 6.13e+07  -4.0 9.14e-10 2.53e-10f  2\n",
      "   2  3.4427268e+02 1.00e+04 1.51e+03  -1.0 1.31e+07   1.8 9.44e-10 3.44e-10f  2\n",
      "   3r 3.4427268e+02 1.00e+04 9.99e+02   4.0 0.00e+00   2.3 0.00e+00 2.18e-10R  2\n",
      "WARNING: Problem in step computation; switching to emergency mode.\n",
      "Restoration phase is called at point that is almost feasible,\n",
      "  with constraint violation 6.788320e-14. Abort.\n",
      "Restoration phase in the restoration phase failed.\n",
      "\n",
      "Number of Iterations....: 3\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   3.4427267686723201e+02    3.4427267686723201e+02\n",
      "Dual infeasibility......:   6.1514343960852980e+00    6.1514343960852980e+00\n",
      "Constraint violation....:   9.9998230165970199e+03    9.9998230165970199e+03\n",
      "Complementarity.........:   9.9999999824450853e+01    9.9999999824450853e+01\n",
      "Overall NLP error.......:   9.9998230165970199e+03    9.9998230165970199e+03\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 8\n",
      "Number of objective gradient evaluations             = 5\n",
      "Number of equality constraint evaluations            = 8\n",
      "Number of inequality constraint evaluations          = 8\n",
      "Number of equality constraint Jacobian evaluations   = 5\n",
      "Number of inequality constraint Jacobian evaluations = 5\n",
      "Number of Lagrangian Hessian evaluations             = 4\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      3.292\n",
      "Total CPU secs in NLP function evaluations           =      0.016\n",
      "\n",
      "EXIT: Restoration Failed!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot load a SolverResults object with bad status: error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 265>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    258\u001b[0m solver\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtol\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-9\u001b[39m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# solver.options['print_level'] = 5  # Adjust based on your needs\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m# # solver.options['max_cpu_time'] = 600  # Limit solver CPU time to 10 minutes\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# solver.options['print_level'] = 10    # Increase verbosity for more detailed log output\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# solver.options['hessian_approximation'] = 'limited-memory'  # Useful for large-scale problems\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtee\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wangh\\env\\lib\\site-packages\\pyomo\\opt\\base\\solvers.py:627\u001b[0m, in \u001b[0;36mOptSolver.solve\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_solutions:\n\u001b[1;32m--> 627\u001b[0m         \u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolutions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m            \u001b[49m\u001b[43mselect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdefault_variable_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_variable_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m         result\u001b[38;5;241m.\u001b[39m_smap_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    632\u001b[0m         result\u001b[38;5;241m.\u001b[39msolution\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[1;32mc:\\Users\\wangh\\env\\lib\\site-packages\\pyomo\\core\\base\\PyomoModel.py:226\u001b[0m, in \u001b[0;36mModelSolutions.load_from\u001b[1;34m(self, results, allow_consistent_values_for_fixed_vars, comparison_tolerance_for_fixed_vars, ignore_invalid_labels, id, delete_symbol_map, clear, default_variable_value, select, ignore_fixed_vars)\u001b[0m\n\u001b[0;32m    222\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    223\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading a SolverResults object with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    224\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maborted\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m status, but containing a solution\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 226\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot load a SolverResults object \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    227\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith bad status: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m                          \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(results\u001b[38;5;241m.\u001b[39msolver\u001b[38;5;241m.\u001b[39mstatus))\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clear:\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;66;03m# Clear the solutions, but not the symbol map\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear(clear_symbol_maps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot load a SolverResults object with bad status: error"
     ]
    }
   ],
   "source": [
    "model         = AbstractModel()\n",
    "\n",
    "# -- variable definition -- #\n",
    "\n",
    "# defining time as continous variable\n",
    "model.t       = ContinuousSet(bounds=[0, tt1[-1]])\n",
    "\n",
    "\n",
    "# defining measurement times\n",
    "model.tm      = Set(within=model.t)\n",
    "\n",
    "\n",
    "\n",
    "# defining measured values as parameters\n",
    "model.x1_noise = Param(model.tm)\n",
    "model.n1_noise = Param(model.tm)\n",
    "model.q1_noise = Param(model.tm)\n",
    "model.f1_noise = Param(model.tm)\n",
    "\n",
    "# defining state variables\n",
    "model.x1 = Var(model.t, within=PositiveReals)#initialize=Xt1[0]) \n",
    "model.n1 = Var(model.t, within=PositiveReals)#,initialize=Xt1[1])\n",
    "model.q1 = Var(model.t, within=PositiveReals)#,initialize=Xt1[2])\n",
    "model.f1 = Var(model.t, within=PositiveReals)#,initialize=Xt1[3]) \n",
    "\n",
    "model.V1 = Var(model.t, within=PositiveReals)#,initialize=Xt1[4])  \n",
    "\n",
    "\n",
    "model.F_in1 = Var(model.t, within=NonNegativeReals,initialize=float(mu1[0][0]))\n",
    "\n",
    "model.I1 = Var(model.t, within=NonNegativeReals,initialize=float(mu1[0][1]))\n",
    "\n",
    "model.N_in = Param(initialize=100)\n",
    "\n",
    "\n",
    "\n",
    "def F_in1_def(model, t):\n",
    "    if t <= tf_N*1:\n",
    "        return model.F_in1[t] == float(mu1[0][0])\n",
    "    elif tf_N*1 < t <= tf_N*2:\n",
    "        return model.F_in1[t] == float(mu1[1][0])\n",
    "    \n",
    "    elif tf_N*2 < t <= tf_N*3:\n",
    "        return model.F_in1[t] == float(mu1[2][0])\n",
    "        \n",
    "    # elif tf_N*3 < t <= tf_N*4:\n",
    "    #     return m.Fn[t] == Fcn[3]\n",
    "    else:\n",
    "        return model.F_in1[t] == float(mu1[3][0])\n",
    "model.F_in1_constr = Constraint(model.t, rule=F_in1_def)\n",
    "\n",
    "def I1_def(model, t):\n",
    "    if t <= tf_N*1:\n",
    "        return model.I1[t] == float(mu1[0][1])\n",
    "    elif tf_N*1 < t <= tf_N*2:\n",
    "        return model.I1[t] == float(mu1[1][1])\n",
    "    \n",
    "    elif tf_N*2 < t <= tf_N*3:\n",
    "        return model.I1[t] == float(mu1[2][1])\n",
    "        \n",
    "    # elif tf_N*3 < t <= tf_N*4:\n",
    "    #     return m.Fn[t] == Fcn[3]\n",
    "    else:\n",
    "        return model.I1[t] == float(mu1[3][1])\n",
    "model.I1_constr = Constraint(model.t, rule=I1_def)\n",
    "\n",
    "\n",
    "\n",
    "# defining parameters to be determined\n",
    "model.I = RangeSet(no_euron) # define number of neurons\n",
    "model.J = RangeSet(3) # number of inputs\n",
    "model.k = RangeSet(1)\n",
    "init_dict_w1 = {(1,1):np.random.normal(0, 1)}\n",
    "init_dict_b1 = {(1,1):np.random.normal(0, 1)}\n",
    "init_dict_w2 = {(1,1):np.random.normal(0, 1)}\n",
    "# init_dict_b2 = {(1,1):0}\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1,no_euron+1): # range of the number of neuron\n",
    "    for j in range(1,4):# range of the number of inputs\n",
    "        # print (i,j)\n",
    "        init_dict_ij = {(i,j):np.random.normal(0, 0.1)}\n",
    "        init_dict_w1.update(init_dict_ij)\n",
    "model.w1 = Var(model.I,model.J, initialize=init_dict_w1,bounds = (-1,1))\n",
    "\n",
    "for i in range(1,2): # for 1 layer this is fixed\n",
    "    for j in range(1,no_euron+1): # range of the number of neuron\n",
    "        # print (i,j)\n",
    "        init_dict_ij = {(i,j):np.random.normal(0, 0.1)}\n",
    "        init_dict_b1.update(init_dict_ij)\n",
    "model.b1 = Var(model.k,model.I,initialize=init_dict_b1,bounds = (-1,1))\n",
    "\n",
    "for i in range(1,2):# for 1 layer this is fixed\n",
    "    for j in range(1,no_euron+1):# range of the number of neuron\n",
    "        # print (i,j)\n",
    "        init_dict_ij = {(i,j):np.random.normal(0, 0.1)}\n",
    "        init_dict_w2.update(init_dict_ij)\n",
    "model.w2           = Var(model.k,model.I,initialize=init_dict_w2,bounds = (-1,1))\n",
    "model.b2           = Var(initialize=0,bounds = (-1,1))\n",
    "\n",
    "model.node1 = Var(model.k,model.I,model.t,initialize=0.1,bounds = (-1,1))\n",
    "\n",
    "\n",
    "model.ud               = Var(domain = Reals, bounds=(0,0.1),  initialize=0)\n",
    "model.un               = Var(domain = Reals, bounds=(0,5),  initialize=2.8)\n",
    "model.kn               = Var(domain = Reals, bounds=(0,2),  initialize=1.4)\n",
    "model.theta            = Var(domain = Reals, bounds=(5,10),  initialize=7.5)\n",
    "model.gamma            = Var(domain = Reals, bounds=(5,10),  initialize=8.4)\n",
    "model.epsilon          = Var(domain = Reals, bounds=(0,1),  initialize=0.1)\n",
    "\n",
    "\n",
    "# Define u\n",
    "model.u1     = Var(model.t,domain = NonNegativeReals, bounds=(0,0.1),initialize=0.05)\n",
    "\n",
    "\n",
    "\n",
    "# defining derivatives\n",
    "model.x1dot = DerivativeVar(model.x1, wrt=model.t,domain = Reals,initialize = dXdt1[0])\n",
    "model.n1dot = DerivativeVar(model.n1, wrt=model.t,domain = Reals,initialize = dXdt1[1])\n",
    "model.q1dot = DerivativeVar(model.q1, wrt=model.t,domain = Reals,initialize = dXdt1[2])\n",
    "model.f1dot = DerivativeVar(model.f1, wrt=model.t,domain = Reals,initialize = dXdt1[3])\n",
    "model.V1dot = DerivativeVar(model.V1, wrt=model.t,domain = Reals,initialize = dXdt1[4])\n",
    "# differential equation for u, x, n#\n",
    "\n",
    "# EXP1 ------------------------------------\n",
    "def NN_node11_exp1(model,t):\n",
    "\n",
    "    return model.node1[1,1,t] == tanh(model.x1[t]/x_max*model.w1[1,1]+model.q1[t]/q_max*model.w1[1,2]+ model.I1[t]/I_max *model.w1[1,3] +model.b1[1,1])\n",
    "model.NN_node11_exp1_cons = Constraint(model.t, rule = NN_node11_exp1)\n",
    "\n",
    "def NN_node12_exp1(model,t):\n",
    "\n",
    "    return model.node1[1,2,t] == tanh(model.x1[t]/x_max*model.w1[2,1]+model.q1[t]/q_max*model.w1[2,2]+ model.I1[t]/I_max *model.w1[2,3] +model.b1[1,2])\n",
    "model.NN_node12_exp1_cons = Constraint(model.t, rule = NN_node12_exp1)\n",
    "\n",
    "def NN_node13_exp1(model,t):\n",
    "    return model.node1[1,3,t] == tanh(model.x1[t]/x_max*model.w1[3,1]+model.q1[t]/q_max*model.w1[3,2]+ model.I1[t]/I_max *model.w1[3,3] + model.b1[1,3])\n",
    "\n",
    "model.NN_node13_exp1_cons = Constraint(model.t, rule = NN_node13_exp1)\n",
    "\n",
    "def NN_node14_exp1(model,t):\n",
    "    return model.node1[1,4,t] == tanh(model.x1[t]/x_max*model.w1[4,1]+model.q1[t]/q_max*model.w1[4,2]+ model.I1[t]/I_max *model.w1[4,3] + model.b1[1,4])\n",
    "\n",
    "model.NN_node14_exp1_cons = Constraint(model.t, rule = NN_node14_exp1)\n",
    "\n",
    "def NN_node15_exp1(model,t):\n",
    "    return model.node1[1,5,t] == tanh(model.x1[t]/x_max*model.w1[5,1]+model.q1[t]/q_max*model.w1[5,2]+ model.I1[t]/I_max *model.w1[5,3] + model.b1[1,5])\n",
    "\n",
    "model.NN_node15_exp1_cons = Constraint(model.t, rule = NN_node15_exp1)\n",
    "\n",
    "def NN_node16_exp1(model,t):\n",
    "    return model.node1[1,6,t] == tanh(model.x1[t]/x_max*model.w1[6,1]+model.q1[t]/q_max*model.w1[6,2]+ model.I1[t]/I_max *model.w1[6,3] + model.b1[1,6])\n",
    "\n",
    "model.NN_node16_exp1_cons = Constraint(model.t, rule = NN_node16_exp1)\n",
    "\n",
    "def NN_node17_exp1(model,t):\n",
    "    return model.node1[1,7,t] == tanh(model.x1[t]/x_max*model.w1[7,1]+model.q1[t]/q_max*model.w1[7,2]+ model.I1[t]/I_max *model.w1[7,3] + model.b1[1,7])\n",
    "\n",
    "model.NN_node17_exp1_cons = Constraint(model.t, rule = NN_node17_exp1)\n",
    "\n",
    "\n",
    "\n",
    "def u1_con_exp1(model,t):\n",
    "    return model.u1[t] == model.node1[1,1,t]*model.w2[1,1] + model.node1[1,2,t]*model.w2[1,2] + model.node1[1,3,t]*model.w2[1,3] + model.node1[1,4,t]*model.w2[1,4] + model.node1[1,5,t]*model.w2[1,5] + model.node1[1,6,t]*model.w2[1,6] + model.node1[1,7,t]*model.w2[1,7] + model.b2\n",
    "model.u1_con_exp1  =Constraint(model.t,rule = u1_con_exp1)\n",
    "\n",
    "def u1_e1_const(model, t):\n",
    "  return model.u1[t] >= 0\n",
    "model.u1_e1_const = Constraint(model.t, rule = u1_e1_const)\n",
    "\n",
    "\n",
    "def dxdt1(model,t):\n",
    "    if t == 0:\n",
    "        return Constraint.Skip\n",
    "    return model.x1dot[t] == -model.F_in1[t]/model.V1[t]*model.x1[t] + model.u1[t] * model.x1[t] - model.ud * model.x1[t]\n",
    "model.dxdtcon1 = Constraint(model.t, rule = dxdt1)\n",
    "\n",
    "def dndt1(model,t):\n",
    "    if t == 0:\n",
    "        return Constraint.Skip\n",
    "    return model.n1dot[t] == model.F_in1[t]*(model.N_in - model.n1[t])/model.V1[t]-model.un*(model.n1[t]/(model.n1[t]+model.kn))*model.x1[t]\n",
    "model.dndtcon1 = Constraint(model.t, rule = dndt1)\n",
    "\n",
    "def dqdt1(model,t):\n",
    "    if t == 0:\n",
    "        return Constraint.Skip\n",
    "    return model.q1dot[t] == model.F_in1[t]*(model.N_in - model.n1[t])/(model.V1[t]*model.x1[t]) +model.un*(model.n1[t]/(model.n1[t]+model.kn)) +model.F_in1[t]*model.q1[t]/model.V1[t] - (model.u1[t]-model.ud)*model.q1[t]\n",
    "model.dqdtcon = Constraint(model.t, rule = dqdt1)\n",
    "\n",
    "def dfdt1(model,t):\n",
    "    if t == 0:\n",
    "        return Constraint.Skip\n",
    "    return model.f1dot[t] == model.u1[t]*(model.theta*model.q1[t]-model.epsilon*model.f1[t]) - model.gamma*model.un*(model.n1[t]/(model.n1[t]+model.kn)) + model.ud*model.epsilon*model.f1[t]\n",
    "model.dfdtcon1 = Constraint(model.t, rule = dfdt1)\n",
    "\n",
    "def dVdt1(model,t):\n",
    "    if t == 0:\n",
    "        return Constraint.Skip\n",
    "    return model.V1dot[t] == model.F_in1[t]\n",
    "model.dVdtcon1 = Constraint(model.t, rule = dVdt1)\n",
    "\n",
    "\n",
    "number_datapoints1 = xobs1.shape[1]\n",
    "number_datapoints2 = xobs2.shape[1]\n",
    "number_datapoints3 = xobs3.shape[1]\n",
    "number_datapoints4 = xobs4.shape[1]\n",
    "\n",
    "\n",
    "number_spc1 = xobs1.shape[0]\n",
    "number_spc2 = xobs2.shape[0]\n",
    "number_spc3 = xobs3.shape[0]\n",
    "number_spc4 = xobs4.shape[0]\n",
    " \n",
    "\n",
    "def obj(model):\n",
    "\n",
    " \n",
    "\n",
    "    variance1    = (sum((model.x1[t]-model.x1_noise[t])**2 for t in model.tm)+sum((model.n1[t]-model.n1_noise[t])**2 for t in model.tm)+sum((model.q1[t]-model.q1_noise[t])**2 for t in model.tm)+sum((model.f1[t]-model.f1_noise[t])**2 for t in model.tm))/(number_datapoints1 * number_spc1)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "    obj1 = (sum((model.x1[t]-model.x1_noise[t])**2 for t in model.tm)+sum((model.n1[t]-model.n1_noise[t])**2 for t in model.tm)+sum((model.q1[t]-model.q1_noise[t])**2 for t in model.tm)+sum((model.f1[t]-model.f1_noise[t])**2 for t in model.tm))/2/(variance1 + 1e-10) - (number_datapoints1 * number_spc1)*log(1/(sqrt(2*3.14159*(variance1 + 1e-10))))\n",
    "\n",
    "\n",
    "    return obj1 \n",
    "\n",
    "    # return variance1+variance2+variance3\n",
    "\n",
    "model.obj = Objective(rule=obj)\n",
    "\n",
    "\n",
    "# def obj(model):\n",
    "#     return 1/2*(sum(((model.x1[t]-model.x1_noise[t])**2/std_x1**2) +((model.n1[t]-model.n1_noise[t])**2/std_n1**2) for t in model.tm)+sum(((model.x2[t]-model.x2_noise[t])**2/std_x2**2) +((model.n2[t]-model.n2_noise[t])**2/std_n2**2) for t in model.tm)+ sum(((model.x3[t]-model.x3_noise[t])**2/std_x3**2) +((model.n3[t]-model.n3_noise[t])**2/std_n3**2) for t in model.tm))\n",
    "# model.obj = Objective(rule=obj)\n",
    "\n",
    "\n",
    "# -- model display -- #\n",
    "\n",
    "# -- creating optimization problem -- #\n",
    "instance = model.create_instance(data_init)\n",
    "instance.x1[0].fix(0.18)\n",
    "instance.n1[0].fix(N1[0])\n",
    "instance.q1[0].fix(80)\n",
    "instance.f1[0].fix(120)\n",
    "instance.V1[0].fix(0.5)\n",
    "\n",
    "discretizer = TransformationFactory('dae.collocation')\n",
    "discretizer.apply_to(instance,nfe=50,ncp=3,wrt=instance.t,scheme='LAGRANGE-RADAU')\n",
    "\n",
    "\n",
    "    # fix initial value\n",
    "\n",
    "solver=SolverFactory('ipopt')\n",
    "solver.options['max_iter'] = 100000\n",
    "solver.options['tol'] = 1e-9\n",
    "# solver.options['print_level'] = 5  # Adjust based on your needs\n",
    "\n",
    "# # solver.options['max_cpu_time'] = 600  # Limit solver CPU time to 10 minutes\n",
    "# solver.options['print_level'] = 10    # Increase verbosity for more detailed log output\n",
    "# solver.options['hessian_approximation'] = 'limited-memory'  # Useful for large-scale problems\n",
    "\n",
    "results = solver.solve(instance, tee=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
